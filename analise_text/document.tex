\documentclass[]{report}
\usepackage{amssymb,amsfonts,amsmath,mathtext,cite,enumerate,float}
\usepackage[pdftex]{graphicx} 
\graphicspath{{images/}}
\usepackage[T2A]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage[english, russian]{babel}

% Title Page
\title{Первое задание по курсу NLP}
\author{Малюгина Ольга}


\begin{document}
\maketitle

\begin{abstract}
	В данном задании необходимо исслодовать и применить на практике следующие умения и методы:
	\begin{itemize}
		\item предобработка текстов;
		\item использование словарей;
		\item лемматизация, нахождение корня;
		\item применение N-грамм, коллокациий;
		\item применение матричных разложений;
		\item использование дистрибуционной семантики;
		\item взвешивание признаков
		\item применение классификаторов;
		\item построение ансамблей различных классификаторов и методов;		
	\end{itemize}
	Все операции производились над четырмя массивами данных.
\end{abstract}

\section{polarity dataset}
В датасете представлены 1000 позитивных и 1000 негативных рецензий.Необходимо постоить классификатор, который по рецензии определяет ее настроение.
\subsection{Предобработка текстов}
Вначале удаляем все лишние символы (запятые, скобки, точки и т.д.).
Делается это из предположения, что количество восклицательных и вопросительных знаков, запятые и т.д. зависят от эмоциональности писавшего и от его грамотности. А эти факторы не должны зависеть от настроения рецензии и качества произведения.

Также отбрасываем стоп слова - исчезает около 100 (из ~35000) самых часто встречаемых слов.
Далее отбрасываем слова, встречающиеся во всех рецензих реже пяти раз. Это около 25 000 тысяч слов.
Также не учитываем слова длиннее 13 символов и короче 5ти. В итоге осталось ~12000 слов.

Далее от каждого слова оставляем лишь корень. И оставляем только начальную форму. (для различных признаков)
\subsection{Выделение признаков и классификация}
\subsubsection{эксперимент 0}
В качестве вектора признаков возьмом вектор, соответствующий леммингованным оставшимся словам и на соответствующие слову в рецензии ячейки запишем частоту слова в рецензии. Получим сильно разреженную матрицу.
Применим к ней PCA уменьшим размерность.

На получиные данные натравим различные классификаторы (качество считается кросс-валидацией по 10 блокам, берем среднее значение).
Применяемые классификаторы: SVM(с линейным ядром), Random tree, Random forest из sklearn.

Самое наилучшее качество при уменьшении размерности до 300 и использовании SVM - 0.8 (худшее при кросс-валидации - 0.78)

При использовании для сокращения размерности SVD разложение качество немного улучшается (на 0,01) - но не принципиально.

\subsubsection{эксперимент 1}
В качестве вектора признаков возьмом вектор, соответствующий леммингованным оставшимся словам и на соответствующие слову в рецензии ячейки запишем частоту слова в рецензии. Получим сильно разреженную матрицу.
Применим к ней PCA уменьшим размерность.

На получиные данные натравим различные классификаторы (качество считается кросс-валидацией по 10 блокам, берем среднее значение).
Применяемые классификаторы: SVM(с линейным ядром), Random tree, Random forest из sklearn.

Самое наилучшее качество при уменьшении размерности до 300 и использовании SVM - 0.8 (худшее при кросс-валидации - 0.78)

При использовании для сокращения размерности SVD разложение качество немного улучшается (на 0,01) - но не принципиально.
\end{document}          
